{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.fromFile = exports.FileTokenizer = void 0;\n\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\n\nconst peek_readable_1 = require(\"peek-readable\");\n\nconst fs = require(\"./FsPromise\");\n\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n  constructor(fd, fileInfo) {\n    super(fileInfo);\n    this.fd = fd;\n  }\n  /**\n   * Read buffer from file\n   * @param buffer\n   * @param options - Read behaviour options\n   * @returns Promise number of bytes read\n   */\n\n\n  async readBuffer(buffer, options) {\n    let offset = 0;\n    let length = buffer.length;\n\n    if (options) {\n      if (options.position) {\n        if (options.position < this.position) {\n          throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n\n        this.position = options.position;\n      }\n\n      if (Number.isInteger(options.length)) {\n        length = options.length;\n      } else {\n        length -= options.offset || 0;\n      }\n\n      if (options.offset) {\n        offset = options.offset;\n      }\n    }\n\n    if (length === 0) {\n      return Promise.resolve(0);\n    }\n\n    const res = await fs.read(this.fd, buffer, offset, length, this.position);\n    this.position += res.bytesRead;\n\n    if (res.bytesRead < length && (!options || !options.mayBeLess)) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n  /**\n   * Peek buffer from file\n   * @param buffer\n   * @param options - Read behaviour options\n   * @returns Promise number of bytes read\n   */\n\n\n  async peekBuffer(buffer, options) {\n    let offset = 0;\n    let length = buffer.length;\n    let position = this.position;\n\n    if (options) {\n      if (options.position) {\n        if (options.position < this.position) {\n          throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n\n        position = options.position;\n      }\n\n      if (Number.isInteger(options.length)) {\n        length = options.length;\n      } else {\n        length -= options.offset || 0;\n      }\n\n      if (options.offset) {\n        offset = options.offset;\n      }\n    }\n\n    if (length === 0) {\n      return Promise.resolve(0);\n    }\n\n    const res = await fs.read(this.fd, buffer, offset, length, position);\n\n    if ((!options || !options.mayBeLess) && res.bytesRead < length) {\n      throw new peek_readable_1.EndOfStreamError();\n    }\n\n    return res.bytesRead;\n  }\n  /**\n   * @param length - Number of bytes to ignore\n   * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\n   */\n\n\n  async ignore(length) {\n    const bytesLeft = this.fileInfo.size - this.position;\n\n    if (length <= bytesLeft) {\n      this.position += length;\n      return length;\n    } else {\n      this.position += bytesLeft;\n      return bytesLeft;\n    }\n  }\n\n  async close() {\n    return fs.close(this.fd);\n  }\n\n}\n\nexports.FileTokenizer = FileTokenizer;\n\nasync function fromFile(sourceFilePath) {\n  const stat = await fs.stat(sourceFilePath);\n\n  if (!stat.isFile) {\n    throw new Error(`File not a file: ${sourceFilePath}`);\n  }\n\n  const fd = await fs.open(sourceFilePath, 'r');\n  return new FileTokenizer(fd, {\n    path: sourceFilePath,\n    size: stat.size\n  });\n}\n\nexports.fromFile = fromFile;","map":{"version":3,"sources":["C:/Users/harpe/Documents/molten-sample-imprint/frontend/node_modules/strtok3/lib/FileTokenizer.js"],"names":["Object","defineProperty","exports","value","fromFile","FileTokenizer","AbstractTokenizer_1","require","peek_readable_1","fs","AbstractTokenizer","constructor","fd","fileInfo","readBuffer","buffer","options","offset","length","position","Error","Number","isInteger","Promise","resolve","res","read","bytesRead","mayBeLess","EndOfStreamError","peekBuffer","ignore","bytesLeft","size","close","sourceFilePath","stat","isFile","open","path"],"mappings":"AAAA;;AACAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;AACAD,OAAO,CAACE,QAAR,GAAmBF,OAAO,CAACG,aAAR,GAAwB,KAAK,CAAhD;;AACA,MAAMC,mBAAmB,GAAGC,OAAO,CAAC,qBAAD,CAAnC;;AACA,MAAMC,eAAe,GAAGD,OAAO,CAAC,eAAD,CAA/B;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,aAAD,CAAlB;;AACA,MAAMF,aAAN,SAA4BC,mBAAmB,CAACI,iBAAhD,CAAkE;AAC9DC,EAAAA,WAAW,CAACC,EAAD,EAAKC,QAAL,EAAe;AACtB,UAAMA,QAAN;AACA,SAAKD,EAAL,GAAUA,EAAV;AACH;AACD;;;;;;;;AAMA,QAAME,UAAN,CAAiBC,MAAjB,EAAyBC,OAAzB,EAAkC;AAC9B,QAAIC,MAAM,GAAG,CAAb;AACA,QAAIC,MAAM,GAAGH,MAAM,CAACG,MAApB;;AACA,QAAIF,OAAJ,EAAa;AACT,UAAIA,OAAO,CAACG,QAAZ,EAAsB;AAClB,YAAIH,OAAO,CAACG,QAAR,GAAmB,KAAKA,QAA5B,EAAsC;AAClC,gBAAM,IAAIC,KAAJ,CAAU,uEAAV,CAAN;AACH;;AACD,aAAKD,QAAL,GAAgBH,OAAO,CAACG,QAAxB;AACH;;AACD,UAAIE,MAAM,CAACC,SAAP,CAAiBN,OAAO,CAACE,MAAzB,CAAJ,EAAsC;AAClCA,QAAAA,MAAM,GAAGF,OAAO,CAACE,MAAjB;AACH,OAFD,MAGK;AACDA,QAAAA,MAAM,IAAIF,OAAO,CAACC,MAAR,IAAkB,CAA5B;AACH;;AACD,UAAID,OAAO,CAACC,MAAZ,EAAoB;AAChBA,QAAAA,MAAM,GAAGD,OAAO,CAACC,MAAjB;AACH;AACJ;;AACD,QAAIC,MAAM,KAAK,CAAf,EAAkB;AACd,aAAOK,OAAO,CAACC,OAAR,CAAgB,CAAhB,CAAP;AACH;;AACD,UAAMC,GAAG,GAAG,MAAMhB,EAAE,CAACiB,IAAH,CAAQ,KAAKd,EAAb,EAAiBG,MAAjB,EAAyBE,MAAzB,EAAiCC,MAAjC,EAAyC,KAAKC,QAA9C,CAAlB;AACA,SAAKA,QAAL,IAAiBM,GAAG,CAACE,SAArB;;AACA,QAAIF,GAAG,CAACE,SAAJ,GAAgBT,MAAhB,KAA2B,CAACF,OAAD,IAAY,CAACA,OAAO,CAACY,SAAhD,CAAJ,EAAgE;AAC5D,YAAM,IAAIpB,eAAe,CAACqB,gBAApB,EAAN;AACH;;AACD,WAAOJ,GAAG,CAACE,SAAX;AACH;AACD;;;;;;;;AAMA,QAAMG,UAAN,CAAiBf,MAAjB,EAAyBC,OAAzB,EAAkC;AAC9B,QAAIC,MAAM,GAAG,CAAb;AACA,QAAIC,MAAM,GAAGH,MAAM,CAACG,MAApB;AACA,QAAIC,QAAQ,GAAG,KAAKA,QAApB;;AACA,QAAIH,OAAJ,EAAa;AACT,UAAIA,OAAO,CAACG,QAAZ,EAAsB;AAClB,YAAIH,OAAO,CAACG,QAAR,GAAmB,KAAKA,QAA5B,EAAsC;AAClC,gBAAM,IAAIC,KAAJ,CAAU,uEAAV,CAAN;AACH;;AACDD,QAAAA,QAAQ,GAAGH,OAAO,CAACG,QAAnB;AACH;;AACD,UAAIE,MAAM,CAACC,SAAP,CAAiBN,OAAO,CAACE,MAAzB,CAAJ,EAAsC;AAClCA,QAAAA,MAAM,GAAGF,OAAO,CAACE,MAAjB;AACH,OAFD,MAGK;AACDA,QAAAA,MAAM,IAAIF,OAAO,CAACC,MAAR,IAAkB,CAA5B;AACH;;AACD,UAAID,OAAO,CAACC,MAAZ,EAAoB;AAChBA,QAAAA,MAAM,GAAGD,OAAO,CAACC,MAAjB;AACH;AACJ;;AACD,QAAIC,MAAM,KAAK,CAAf,EAAkB;AACd,aAAOK,OAAO,CAACC,OAAR,CAAgB,CAAhB,CAAP;AACH;;AACD,UAAMC,GAAG,GAAG,MAAMhB,EAAE,CAACiB,IAAH,CAAQ,KAAKd,EAAb,EAAiBG,MAAjB,EAAyBE,MAAzB,EAAiCC,MAAjC,EAAyCC,QAAzC,CAAlB;;AACA,QAAI,CAAC,CAACH,OAAD,IAAY,CAACA,OAAO,CAACY,SAAtB,KAAoCH,GAAG,CAACE,SAAJ,GAAgBT,MAAxD,EAAgE;AAC5D,YAAM,IAAIV,eAAe,CAACqB,gBAApB,EAAN;AACH;;AACD,WAAOJ,GAAG,CAACE,SAAX;AACH;AACD;;;;;;AAIA,QAAMI,MAAN,CAAab,MAAb,EAAqB;AACjB,UAAMc,SAAS,GAAG,KAAKnB,QAAL,CAAcoB,IAAd,GAAqB,KAAKd,QAA5C;;AACA,QAAID,MAAM,IAAIc,SAAd,EAAyB;AACrB,WAAKb,QAAL,IAAiBD,MAAjB;AACA,aAAOA,MAAP;AACH,KAHD,MAIK;AACD,WAAKC,QAAL,IAAiBa,SAAjB;AACA,aAAOA,SAAP;AACH;AACJ;;AACD,QAAME,KAAN,GAAc;AACV,WAAOzB,EAAE,CAACyB,KAAH,CAAS,KAAKtB,EAAd,CAAP;AACH;;AA9F6D;;AAgGlEV,OAAO,CAACG,aAAR,GAAwBA,aAAxB;;AACA,eAAeD,QAAf,CAAwB+B,cAAxB,EAAwC;AACpC,QAAMC,IAAI,GAAG,MAAM3B,EAAE,CAAC2B,IAAH,CAAQD,cAAR,CAAnB;;AACA,MAAI,CAACC,IAAI,CAACC,MAAV,EAAkB;AACd,UAAM,IAAIjB,KAAJ,CAAW,oBAAmBe,cAAe,EAA7C,CAAN;AACH;;AACD,QAAMvB,EAAE,GAAG,MAAMH,EAAE,CAAC6B,IAAH,CAAQH,cAAR,EAAwB,GAAxB,CAAjB;AACA,SAAO,IAAI9B,aAAJ,CAAkBO,EAAlB,EAAsB;AAAE2B,IAAAA,IAAI,EAAEJ,cAAR;AAAwBF,IAAAA,IAAI,EAAEG,IAAI,CAACH;AAAnC,GAAtB,CAAP;AACH;;AACD/B,OAAO,CAACE,QAAR,GAAmBA,QAAnB","sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromFile = exports.FileTokenizer = void 0;\nconst AbstractTokenizer_1 = require(\"./AbstractTokenizer\");\nconst peek_readable_1 = require(\"peek-readable\");\nconst fs = require(\"./FsPromise\");\nclass FileTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\n    constructor(fd, fileInfo) {\n        super(fileInfo);\n        this.fd = fd;\n    }\n    /**\n     * Read buffer from file\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns Promise number of bytes read\n     */\n    async readBuffer(buffer, options) {\n        let offset = 0;\n        let length = buffer.length;\n        if (options) {\n            if (options.position) {\n                if (options.position < this.position) {\n                    throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n                }\n                this.position = options.position;\n            }\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.offset) {\n                offset = options.offset;\n            }\n        }\n        if (length === 0) {\n            return Promise.resolve(0);\n        }\n        const res = await fs.read(this.fd, buffer, offset, length, this.position);\n        this.position += res.bytesRead;\n        if (res.bytesRead < length && (!options || !options.mayBeLess)) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return res.bytesRead;\n    }\n    /**\n     * Peek buffer from file\n     * @param buffer\n     * @param options - Read behaviour options\n     * @returns Promise number of bytes read\n     */\n    async peekBuffer(buffer, options) {\n        let offset = 0;\n        let length = buffer.length;\n        let position = this.position;\n        if (options) {\n            if (options.position) {\n                if (options.position < this.position) {\n                    throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n                }\n                position = options.position;\n            }\n            if (Number.isInteger(options.length)) {\n                length = options.length;\n            }\n            else {\n                length -= options.offset || 0;\n            }\n            if (options.offset) {\n                offset = options.offset;\n            }\n        }\n        if (length === 0) {\n            return Promise.resolve(0);\n        }\n        const res = await fs.read(this.fd, buffer, offset, length, position);\n        if ((!options || !options.mayBeLess) && res.bytesRead < length) {\n            throw new peek_readable_1.EndOfStreamError();\n        }\n        return res.bytesRead;\n    }\n    /**\n     * @param length - Number of bytes to ignore\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\n     */\n    async ignore(length) {\n        const bytesLeft = this.fileInfo.size - this.position;\n        if (length <= bytesLeft) {\n            this.position += length;\n            return length;\n        }\n        else {\n            this.position += bytesLeft;\n            return bytesLeft;\n        }\n    }\n    async close() {\n        return fs.close(this.fd);\n    }\n}\nexports.FileTokenizer = FileTokenizer;\nasync function fromFile(sourceFilePath) {\n    const stat = await fs.stat(sourceFilePath);\n    if (!stat.isFile) {\n        throw new Error(`File not a file: ${sourceFilePath}`);\n    }\n    const fd = await fs.open(sourceFilePath, 'r');\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\n}\nexports.fromFile = fromFile;\n//# sourceMappingURL=FileTokenizer.js.map"]},"metadata":{},"sourceType":"script"}